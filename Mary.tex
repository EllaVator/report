The final step in creating the speaking elevator "Ella" was of course to make it actually talk to the user.
For this a Text-to-Speech system (TTS) had to be used. A text to speech system will read out information to the user, transforming written into spoken text.
Such programs are widely used today. 
There are announcements at the train station informing guests about delays or if there are changes causing a train to depart from a different platform as planned.
There are screenreaders for the visual impaired, which read out the elements of a screen, as well as systems which are used by the speech impaired to communicate and speak in their stead.
One of the most famous talking applications is the Dialogue system "Siri" (Siri inc) which has been used since 2011 on the iPhone. \newline \newline
For our talking elevator we wanted to use an open source TTS. 
We did choose the system Mary for this task.
Not only was it developed in cooperation with the university of Saabrücken, it also offers many advantages to other TTS and therefore seemed perfect for the task.\newline

Written in the programming language Java it was designed in a collaboration between the  "Language Technology Lab" of the DFKI \footnote {(\textbf{D}eutsches-\textbf{F}orschungszentrum für \textbf{K}ünstliche \textbf{I}ntelligenz) - The German Research Centre for Artificial Intelligence} and the faculty for phonetics of the university of Saarbrücken.
As Mary is an open Source project, the code can be read by everyone. Furthermore everyone is also allowed to change and adjust it to ones needs.\newline \newline

The name Mary is an acronym for \newline 
\begin{center}"\textbf{M}odular \textbf{A}rchitecture for \textbf{R}easearch on speech s\textbf{Y}nthesis".\end{center}
This name already states various facts about the system. 
It is build in a "modular architecture" which means that it consists of different components, each dealing with a specific task. We will take a closer look at these in the following subchapter.
The second part of the name states the purpose Mary was developed for.
It was developed for research having a modular structure and also being a open source project makes it really easy to use Mary for any research projects on speech synthesis. \newline \newline
Mary is a multilingual TSS, featuring the languages English (British as well as American), German, Telugu, Turkish, Russian, Swedish and Italian. 
Further languages might be included in the future, but can also be added by any user. \newline \newline
The following information about the structure and components of Mary is taken from the paper: 
The German Text-to-Speech Synthesis System MARY:
A Tool for Research, Development and Teaching by Marc Schröder Marc and Jürgen Trouvain.

\subsubsection {Modules}

Mary is subdivided into different modules. 
This allows the user to take a look at the output of each of those components. 
One could also interchange small details on one component and observe the output on the complete system as well as completely interchanging a component.

\subsubsection* {Input}

Mary accepts different kinds of inputs, the simplest one being plain text. 
But also Mark-up Languages such as SABLE or SSML can be used. 
These are based on the Mark-up Language XML and are developed especially for the use in TTS.

In case of the elevator we only pass the output of the Open Dail Dialogue Manager to Mary, which is plain text.
Any input given to Mary will be transformed into a "MaryXML Mark-up Skeleton". 
A skeleton which already has different slots which will be filled by the system in the other modules.
If the input was already in a form of Mark-up language the keys assigned in this Mark-up Language will be kept and added to the Skeleton some of the values however might be dropped.

\subsubsection* {Tokenizer}

The tokenizer identifies the tokens of a text. The output of this module will be sentences and words which will be marked as such.
Any token will be enclosed by "\textless t\textgreater ...\textless  t\textgreater". 
These marks are however just placeholder. 
Later on, further information will be saved in these slots.
Analogous a sentence is enclosed by "\textless s\textgreater ... \textless s\textgreater". 
Marking a dot as a sentence might seem obvious at first, but can prove quite difficult if there are other tokens in the text which also come with a dot, but do not mark the end of a sentence, such as the dot placed after titles.

\subsubsection* {Preprocessing}

This module, also called "Text-normalisation" does only work on very specific tokens.
It is only needed for acronyms or numbers.
For acronyms, the system will have to decide whether to pronounce them as one word or spell each letter out separately.
Numbers are divided into ordinal and cardinal numbers.

\subsubsection* {Tagger and Chunker}

This module has two different tasks to solve. 
The Chunker labels the constituents in each sentence.
These are distinguished between adjective, nominal and prepositionalphrase. "Chunkie" is used for this task. 
It was developed by Skut and Brants in 1998. 
"TnT", the tagger used was also developed by Brants in 2000. 
It is a statistical POS-tagger working with trigram provabilities \footnote {To assign the correct word class the tagger does not only consider the current word but also the two words which were used last, making it a total of three words.} in order to assign every word its proper word class.
The word classes are provided by the Stuttgard-Tuebinger-Tagset (Schiller et. al., 1997)

The findings of the two components are saved within the placeholders that were created by the tokenizer.
Unfortunately this also means that some of the information given by the Chunker will be lost. This would be the case for local ambiguities.


\subsubsection* {Phonemisation}

This module also describes the work of several smaller steps.
The output of this system will be the transcription of every word into phonetic transcription.
To able to do this however there still needs to be some information extracted.
One of the steps needed is called "inflection endings". 
In this process, the tokens marked in the step "Preprocessing" are reviewed.
With the information given by the Chunker in the earlier steps as well as under the use of the morphologic analyser "Mmorph" (Petitpierre and Russle, 1995) these tokens such as ordinal number can now be expanded.\newline 
In this step Mary will also check a dictionary specifically designed for Mary by the DFKI.
It contains information about the stem of a word as well grammatical information, which reduces the amount of data as regular words can be conjugated and inflected according to those rules.
The lexicon also covers many of the acronyms. 
It can even handle composed words quite will, which is especially important for the German language. \newline 
In case there is no information found about a word in the dictionary the "letter to sound conversion" will be used.
Of course this module can not know whether a word unknown to the system is an acronym or an actual word. 
This problem was solved rather simply. 
All words which have less than five letter will be treated as acronyms and each letter will be pronounced separately. 
In case the word is longer it will be read out as a complete word.
The "letter to sound conversion" (Alan Black et al., 1998) was trained on the dictionary to obtain about how to pronounce a word.
The decomposition was trained statistically on the database CELEX (Baayen et al. 1995).
After decomposing every word they will be matched against a list containing morphemes which change the intonation of a word.
The remaining morphemes are processed according to language specific rules.
Hyphenation will also be defined by phonological principals such as the sonoraty hierarchy of phonemes \footnote {Schröder, Marc, and Trouvain Juergen. "The German text-to-speech synthesis system MARY: A tool for research, development and teaching." International Journal of Speech Technology 6.4 (2003): 365-377.} \newline
After these analysis an algorithm decides which syllable will get the main stress.\newline
The output of this module only contains the SAMPA transcription and a note in case a word was processed by the "Letter to sound conversion". 
Information on intonation will not be seen in the output.

\subsubsection* {Prosody rules}

After the last module has assessed the intonation of a word, this module will analyse the prosody of the entire text.
The end of a sentence is a classic example for the intonation of a sentence, but one of the most important aspect of prosody of a text are the pauses which have to be added to it.
These will be included by the program GToBI (Grice et al., 2002). 
With the aid of GToBI Mary distinguishes between six types of pauses, all being different in their length.
A pause for the end of a paragraph for example will be given the number 6, which is the longest pause there is in Mary.

Again, the work of the chunker and tagger is of great importance for this module.
The output of the chunker will provide information on the structure of the sentence, for example whether a part of a sentence is a \emph{Vorfeld}. \footnote {Marc Schroder and Juergen Trouvain, 2003}
Though not all of the information will be seen in the output of this module, every word will contain a new field called "accent" in its placeholder, where the information about the intonation of the word will be stored.

\subsubsection* {Postlexical and Phonological process}

In this step the data will be revised and everything will be put into context.
Smaller details such as glottal stops or elisions at the end of a word are being added. 
After this step the skeleton which has been created at the beginning of the process is filled with the maximum of information being available to Mary.

\subsubsection* {Calculation of acoustic parameters} 

This module will abandon the structure of the MaryXML structure.
Instead, the output will be a list of segments, their duration and the corresponding F0 value \footnote {The F0 value is a number describing the format 0, or the fundamental frequency of a voice and indicates the pitch.}
"The duration rules" by Brinckmann and Trouvain (2002) were used for this. These were created as an adaptation of the  "Klatt-Rules" (Klatt 1979; Allen et al., 1987) and define how long a tone will be.
The realisation is taken from GtoBI which was used to determine the pauses between the words in the earlier steps.

\subsubsection* {Synthesis}
In this final step the values acquired in earlier steps will at last be converted into sound.
The modular architecture of Mary makes it easy to interchange the synthesis module as long as it supports the format of the output given by the previous module.
Currently MBROLA (Dutroit et al., 1996) is used in by Mary, which was selected as it creates a low distortion in the signal.